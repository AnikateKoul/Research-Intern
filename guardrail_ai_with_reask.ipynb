{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-29T12:49:42.746508400Z",
     "start_time": "2024-05-29T12:49:34.862094100Z"
    }
   },
   "outputs": [],
   "source": [
    "from guardrails import Guard\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the API key for Gemini"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_api_key():\n",
    "    with open('config.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        return config['apiKey']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T12:49:45.643623900Z",
     "start_time": "2024-05-29T12:49:45.620584Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# configuring the gemini model with the api key\n",
    "genai.configure(api_key=load_api_key())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T12:49:47.003000300Z",
     "start_time": "2024-05-29T12:49:46.986879200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configuring the Gemini Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# configurations for the model\n",
    "gen_config = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 64,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T12:49:48.949932100Z",
     "start_time": "2024-05-29T12:49:48.914806Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# selecting the AI model for the response\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash-latest\",\n",
    "    generation_config=gen_config,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T12:49:51.617359100Z",
     "start_time": "2024-05-29T12:49:51.604775500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# for now there is no history for the chat\n",
    "chat_session = model.start_chat(\n",
    "    history=[\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T12:49:53.311524700Z",
     "start_time": "2024-05-29T12:49:53.301235400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining a custom LLM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# This is the function template provided by Guardrails AI to define a custom LLM. Simply call your LLM with a given input and return the string output.\n",
    "\n",
    "def my_llm_api(\n",
    "    prompt: Optional[str] = None,\n",
    "    instruction: Optional[str] = None,\n",
    "    msg_history: Optional[list[dict]] = None,\n",
    "    **kwargs\n",
    ") -> str:\n",
    "    \"\"\"Custom LLM API wrapper.\n",
    "\n",
    "    At least one of prompt, instruction or msg_history should be provided.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to be passed to the LLM API\n",
    "        instruction (str): The instruction to be passed to the LLM API\n",
    "        msg_history (list[dict]): The message history to be passed to the LLM API\n",
    "        **kwargs: Any additional arguments to be passed to the LLM API\n",
    "\n",
    "    Returns:\n",
    "        str: The output of the LLM API\n",
    "    \"\"\"\n",
    "\n",
    "    # Call your LLM API here\n",
    "    llm_output = chat_session.send_message(prompt).text\n",
    "\n",
    "    return llm_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T12:49:55.487525100Z",
     "start_time": "2024-05-29T12:49:55.476766Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using the RAIL spec file to generate response"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Here we import the RAIL spec file and use those configurations to create our guardrail\n",
    "guard = Guard.from_rail('./guardrail.xml')\n",
    "_, validated_output, *rest = guard(\n",
    "    my_llm_api,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T13:03:57.818640700Z",
     "start_time": "2024-05-29T13:03:53.764647200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fees': [{'index': 1, 'name': 'monthly fee', 'explanation': 'A fee charged for maintaining an account.', 'value': 0.01}, {'index': 2, 'name': 'overdraft fee', 'explanation': 'A fee charged for withdrawing more money than is available.', 'value': 0.02}, {'index': 3, 'name': 'atm fee', 'explanation': 'A fee charged for using an ATM outside of the network.', 'value': 0.03}], 'interest_rates': 'Interest rates vary depending on the type of account or loan.'}\n"
     ]
    }
   ],
   "source": [
    "print(validated_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T13:04:46.932829500Z",
     "start_time": "2024-05-29T13:04:46.906217500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
